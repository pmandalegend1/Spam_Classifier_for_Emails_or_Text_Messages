{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97fbd45a-6c1d-42b4-8608-abb1ea81269f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows = 5572 and No. of columns = 2\n",
      "     label                                            message\n",
      "756    ham                            So why didnt you holla?\n",
      "1870   ham                     Mom wants to know where you at\n",
      "3404   ham       Good night my dear.. Sleepwell&amp;Take care\n",
      "1402   ham  Kaiez... Enjoy ur tuition... Gee... Thk e seco...\n",
      "1973   ham  Yes but can we meet in town cos will go to gep...\n",
      "4826   ham         I am going to sleep. I am tired of travel.\n",
      "2054   ham  Oh... I was thkin of goin yogasana at 10 den n...\n",
      "2202   ham  A boy was late 2 home. His father: \"POWER OF F...\n",
      "4128   ham                             Sorry, I'll call later\n",
      "3690   ham                          You still coming tonight?\n",
      "\n",
      "The shape of the Dataset: (5572, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\"\n",
    "df = pd.read_csv(url, sep='\\t', names=['label', 'message'])\n",
    "\n",
    "x , y = df.shape[0], df.shape[1]\n",
    "print(f\"No. of rows = {x} and No. of columns = {y}\")\n",
    "\n",
    "print(df.sample(10))\n",
    "print(f\"\\nThe shape of the Dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9b916e5-507d-4a7a-95c2-ab95964060e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows removed due to duplicates = 403\n",
      "                                                message  \\\n",
      "2604  Im at arestaurant eating squid! i will be out ...   \n",
      "4313           I keep ten rs in my shelf:) buy two egg.   \n",
      "1292  Hey babe! I saw you came online for a second a...   \n",
      "3850                                   U in town alone?   \n",
      "4230  Have you bookedthe hut? And also your time off...   \n",
      "\n",
      "                                          clean_message  \n",
      "2604  im at arestaurant eating squid i will be out a...  \n",
      "4313              i keep ten rs in my shelf buy two egg  \n",
      "1292  hey babe i saw you came online for a second an...  \n",
      "3850                                    u in town alone  \n",
      "4230  have you bookedthe hut and also your time off ...  \n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "ck = df.shape[0]\n",
    "co = x- ck\n",
    "print(f\"No. of rows removed due to duplicates = {co}\")\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "df['clean_message'] = df['message'].apply(clean_text)\n",
    "print(df[['message', 'clean_message']].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05782d14-ed71-4543-bedb-6c45c16be512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape after vectorized: (5169, 8341)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "X = tfidf.fit_transform(df['clean_message'])\n",
    "y = df['label']\n",
    "\n",
    "print(f\"Feature matrix shape after vectorized: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d543e58-3900-4b6e-bfb5-9955f72a58f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of values in training set: 4135\n",
      "No. of values in test set: 1034\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "print(f\"No. of values in training set: {X_train.shape[0]}\")\n",
    "print(f\"No. of values in test set: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45d14c25-233b-4d8a-bdda-f5f41b9549cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f95f485b-ab4f-49d7-956a-ea882ab5c9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Metrics using Multimodal Naive Bias---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98       894\n",
      "        spam       1.00      0.76      0.86       140\n",
      "\n",
      "    accuracy                           0.97      1034\n",
      "   macro avg       0.98      0.88      0.92      1034\n",
      "weighted avg       0.97      0.97      0.97      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"--- Metrics using Multimodal Naive Bias---\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d07d2b1-ac0f-4aeb-b64d-7c3a8af4993e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: 'Congratulations! You won $1000.' -> Result: spam\n",
      "Test 2: 'Request for internship' -> Result: ham\n"
     ]
    }
   ],
   "source": [
    "def predict_spam(text):\n",
    "    cleaned_text = clean_text(text)\n",
    "    vectorized_input = tfidf.transform([cleaned_text])\n",
    "    prediction = model.predict(vectorized_input)\n",
    "    return prediction[0]\n",
    "\n",
    "test_msg1 = \"Congratulations! You won $1000.\"\n",
    "test_msg2 = \"Request for internship\"\n",
    "\n",
    "print(f\"Test 1: '{test_msg1}' -> Result: {predict_spam(test_msg1)}\")\n",
    "print(f\"Test 2: '{test_msg2}' -> Result: {predict_spam(test_msg2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b0d19ba-c446-458e-9b67-9fa86cac858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Feature Importancce (most spam like words)\n",
      "        word  importance\n",
      "2559    free   -5.975126\n",
      "4470  mobile   -6.304349\n",
      "1232   claim   -6.326930\n",
      "7141    text   -6.331545\n",
      "7507     txt   -6.344608\n",
      "6798    stop   -6.419383\n",
      "5879   reply   -6.430322\n",
      "5538   prize   -6.486446\n",
      "7633      ur   -6.486636\n",
      "7636  urgent   -6.667895\n"
     ]
    }
   ],
   "source": [
    "words = tfidf.get_feature_names_out()\n",
    "spam_probs = model.feature_log_prob_[1]\n",
    "\n",
    "word_importance = pd.DataFrame({'word': words, 'importance': spam_probs})\n",
    "print(\"Checking the Feature Importancce (most spam like words)\")\n",
    "print(word_importance.sort_values(by='importance', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da23081a-babc-4365-b47b-a562c225dbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble models (RF & XGB) trained successfully.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_num = y_train.map({'ham': 0, 'spam': 1})\n",
    "y_test_num = y_test.map({'ham': 0, 'spam': 1})\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "xgb_model = XGBClassifier(eval_metric='logloss')\n",
    "rf_model.fit(X_train, y_train_num)\n",
    "xgb_model.fit(X_train, y_train_num)\n",
    "\n",
    "print(\"Ensemble models (RF & XGB) trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "049926eb-2a05-49b3-ae55-8b5c7035db91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy  Precision    Recall  F1-Score\n",
      "2        Random Forest  0.968085   1.000000  0.764286  0.866397\n",
      "0          Naive Bayes  0.967118   1.000000  0.757143  0.861789\n",
      "3              XGBoost  0.966151   0.964602  0.778571  0.861660\n",
      "1  Logistic Regression  0.950677   0.978495  0.650000  0.781116\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "models_list = { \"Naive Bayes\": (model, y_test),\n",
    "    \"Logistic Regression\": (lr_model, y_test),\n",
    "    \"Random Forest\": (rf_model, y_test_num),\n",
    "    \"XGBoost\": (xgb_model, y_test_num)}\n",
    "\n",
    "comparison = []\n",
    "for name, (clf, target) in models_list.items():\n",
    "    preds = clf.predict(X_test)\n",
    "    pos_label = 1 if name in [\"Random Forest\", \"XGBoost\"] else 'spam'\n",
    "\n",
    "    comparison.append({\"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(target, preds),\n",
    "        \"Precision\": precision_score(target, preds, pos_label=pos_label),\n",
    "        \"Recall\": recall_score(target, preds, pos_label=pos_label),\n",
    "        \"F1-Score\": f1_score(target, preds, pos_label=pos_label)})\n",
    "\n",
    "df_metrics = pd.DataFrame(comparison)\n",
    "print(df_metrics.sort_values(by=\"F1-Score\", ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
